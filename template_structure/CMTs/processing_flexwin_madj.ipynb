{
 "metadata": {
  "name": "",
  "signature": "sha256:a17726e04ed6f96194ec58677ae69bfa9c0cbb095ca274326c3ed1633af49d5f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "number_of_tasks=176\n",
      "#%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "number_of_tasks=176\n",
      "number_of_tasks=176\n",
      "from IPython import parallel\n",
      "import time\n",
      "c = parallel.Client()\n",
      "while len(c) != number_of_tasks:\n",
      "    time.sleep(5)\n",
      "    print len(c)\n",
      "    print c.ids\n",
      "print c.ids\n",
      "view = c.load_balanced_view()\n",
      "\n",
      "!date"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "\n",
      "import os,glob\n",
      "import obspy\n",
      "import math\n",
      "\n",
      "import matplotlib\n",
      "matplotlib.use('Agg')\n",
      "import matplotlib.pyplot as plt  \n",
      " \n",
      "import numpy\n",
      "import pandas as ps\n",
      "import operator\n",
      "#affinity  \n",
      "#reset the affinity after importing modules, see http://nbviewer.ipython.org/gist/minrk/5500077\n",
      "\n",
      "import psutil\n",
      "from multiprocessing import cpu_count\n",
      "\n",
      "p = psutil.Process(os.getpid())\n",
      "p.cpu_affinity(range(cpu_count()))\n",
      "print p.cpu_affinity()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#functions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "def get_filteredstations(stationfile='STATIONS_FILTERED'):\n",
      "    \"\"\"return stations list, nets list, lat stations and lon stations\"\"\"\n",
      "    fs=open(stationfile,'r')\n",
      "    stations=numpy.loadtxt(stationfile,usecols=(0,),dtype=(str))\n",
      "    nets=numpy.loadtxt(stationfile,usecols=(1,),dtype=(str))\n",
      "    latstations,lonstations=numpy.loadtxt(stationfile,usecols=(2,3),dtype=(float,float),unpack=True)\n",
      "    return stations,nets,latstations,lonstations\n",
      "\n",
      "def get_eventloc(cmt):\n",
      "    f=open(cmt,'r')\n",
      "    h=f.readline()\n",
      "    lat=h.split()[7]\n",
      "    lon=h.split()[8]\n",
      "    return float(lon),float(lat),h\n",
      "\n",
      "def create_mseed(r):\n",
      "    \"\"\"\n",
      "    create mseed files from semv ascii files in directory r\n",
      "    \n",
      "    r: [DIR iteration]/run[ID]\n",
      "    \"\"\"\n",
      "    #\n",
      "    rid=r.split('/')[-1] #extract id \n",
      "    #\n",
      "    #get seismograms\n",
      "    fname=glob.glob(r+'/OUTPUT_FILES/*.semv')\n",
      "    #\n",
      "    #get stations and cmtsolution\n",
      "    stationfile=r+'/DATA/STATIONS'\n",
      "    stations,nets,latstations,lonstations=get_filteredstations(stationfile=stationfile)\n",
      "    #\n",
      "    #get cmtsolution\n",
      "    cmtfile=r+'/DATA/CMTSOLUTION'\n",
      "    lone,late,h=get_eventloc(cmtfile)\n",
      "    #\n",
      "    traces=[]\n",
      "    for name in fname[:]:\n",
      "        k=name.split('/')[-1].split('.')\n",
      "        station=k[0]\n",
      "        if station in stations:\n",
      "            data=numpy.loadtxt(name)\n",
      "            #os.remove(name)\n",
      "            time=data[:,0]\n",
      "            sampling=(time[2]-time[1])\n",
      "            network=k[1]\n",
      "            station=k[0]\n",
      "            channel=k[2]\n",
      "            stats = {'network': network, 'station': station, 'location': '',\n",
      "             'channel': channel, 'npts': len(data), 'sampling_rate': 1/sampling,\n",
      "             'mseed': {'dataquality': 'D'},'starttime':time[0]}\n",
      "            tr=obspy.Trace(data=data[:,1], header=stats)\n",
      "            traces.append(tr)\n",
      "        else:\n",
      "            os.remove(name) #remove if not in stations\n",
      "    #\n",
      "    if len(traces) > 0:\n",
      "        st=obspy.Stream(traces)\n",
      "        st.write(os.path.join(os.path.dirname(r),rid+'_semv.mseed'),format='MSEED')\n",
      "        return os.getpid(),st\n",
      "    else:\n",
      "        return os.getpid(),0,r,rid,len(fname)\n",
      "\n",
      "def extract_sac(ms):\n",
      "    \"\"\"convert mseed in sac (one sac files for each components)\n",
      "    \n",
      "    ms: name of mseed file (run[ID]_file)\n",
      "    \n",
      "    it assumes to run in [DIR iteration]/\n",
      "    \n",
      "    \"\"\"\n",
      "    rid=os.path.basename(ms).split('_')[0] #get run[id]\n",
      "    path=os.path.dirname(ms)\n",
      "    #\n",
      "    if not os.path.exists(os.path.join(path,rid+'_mseed')):    os.mkdir(os.path.join(path,rid+'_mseed'))\n",
      "    stationfile=os.path.join(rid,'DATA/STATIONS')\n",
      "    cmt=os.path.join(rid,'DATA/CMTSOLUTION')\n",
      "    stations,nets,lat,lon=get_filteredstations(stationfile=stationfile)\n",
      "    lone,late,title=get_eventloc(cmt)\n",
      "    stream=obspy.read(ms)\n",
      "    for v in stream[:]:\n",
      "        name=os.path.join(path,rid+'_mseed',rid+'.'+v.stats.network+'.'+v.stats.station+'..'+v.stats.channel+'.S.SAC')\n",
      "        v.stats.sac = obspy.core.AttribDict()\n",
      "        v.stats.sac.stla = lat[stations==v.stats.station][0]\n",
      "        v.stats.sac.stlo = lon[stations==v.stats.station][0]\n",
      "        v.stats.sac.b = v.stats.starttime-obspy.UTCDateTime(0)\n",
      "        #v.stats.sac.e = v.stats.endtime-obspy.UTCDateTime(0)\n",
      "        v.stats.sac.e = v.stats.sac.b+(v.stats.npts-1)*v.stats.delta\n",
      "        v.stats['coordinates']={'latitude':v.stats.sac.stla,'longitude':v.stats.sac.stlo}\n",
      "        v.stats['distance'] = obspy.core.util.gps2DistAzimuth(v.stats.sac.stla, v.stats.sac.stlo,\n",
      "                                        late, lone)[0]\n",
      "        v.stats.coordinates.latitude=lat[stations==v.stats.station][0]\n",
      "        v.stats.sac.evla = late\n",
      "        v.stats.sac.evlo = lone\n",
      "        v.stats.sac.dist,v.stats.sac.az,v.stats.sac.baz=obspy.core.util.gps2DistAzimuth(v.stats.sac.stla, v.stats.sac.stlo,v.stats.sac.evla, v.stats.sac.evlo)\n",
      "        v.write(name,format='SAC')\n",
      "    stream.write(ms,format='MSEED')\n",
      "    return ms\n",
      "\n",
      "def process_synt(r,f1=10,f2=40,sampling=20):\n",
      "    \"\"\"\n",
      "    processing sac synthethics\n",
      "    \n",
      "    r: directory [DIR iteration]/run[ID]_mseed\n",
      "    \n",
      "    it assumes to run in [DIR iteration]/\n",
      "    \"\"\"\n",
      "    rid=os.path.basename(r).split('_')[0] #get run[id]\n",
      "    #\n",
      "    stationfile=os.path.join(rid,'DATA/STATIONS')\n",
      "    cmt=os.path.join(rid,'DATA/CMTSOLUTION')\n",
      "    #\n",
      "    path2=os.path.dirname(r)\n",
      "    rproc=os.path.join(path2,rid+'_mseed_processed')\n",
      "    if not os.path.exists(rproc):    os.mkdir(rproc)\n",
      "    #\n",
      "    processing_script='process_syn_transf+lphp.pl'\n",
      "    rotate_script='rotate.pl'\n",
      "    !{processing_script} -S -m {cmt} -a {stationfile} -s {sampling} -l -30/299 -f -t {f1}/{f2} -P 3/1 -x {f1}.{f2}.lphp.synt {r}/*.SAC\n",
      "    !mv {r}/*10.40.lphp.synt {rproc}\n",
      "    !{rotate_script} {rproc}/*.?XE.*.{f1}.{f2}.lphp.synt\n",
      "    !rm -f {rproc}/*.?XE.*.{f1}.{f2}.lphp.synt\n",
      "    !rm -f {rproc}/*.?XN.*.{f1}.{f2}.lphp.synt\n",
      "    return r\n",
      "\n",
      "def process_data(r,data_store='/ccc/work/cont005/ra2410/magnonif/DATA_STORE/',sampling=20,t1=10,t2=40):\n",
      "    \"\"\"\n",
      "    processing sac data\n",
      "    \n",
      "    r: directory [DIR iteration]/run[ID]_mseed\n",
      "    \n",
      "    \"\"\"\n",
      "    import datetime\n",
      "    rid=os.path.basename(r).split('_')[0] #get run[id]\n",
      "    respfile=os.path.join(data_store,rid+'_mseed','RESP')\n",
      "    cmt=os.path.join(rid,'DATA/CMTSOLUTION')\n",
      "    store_dir=os.path.join(data_store,rid+'_mseed_processed_'+str(sampling)+'_'+str(t1)+'.'+str(t2))\n",
      "    if not os.path.exists(store_dir):\n",
      "        os.mkdir(store_dir)\n",
      "    else:\n",
      "        d=str(datetime.datetime.fromtimestamp(os.path.getmtime(store_dir))).split()[0]\n",
      "        if not os.path.exists(os.path.join(store_dir+'_'+d)): os.mkdir(store_dir+'_'+d)\n",
      "        !mv {store_dir}/* {store_dir}_{d}\n",
      "    !process_data_transf+lphp.pl -m {cmt} -R {respfile} -s {sampling} -l -30/299 -f -t {t1}/{t2} -P 3/1 -x {t1}.{t2}.lphp.real {r}/*.SAC\n",
      "    !mv {r}/*{t1}.{t2}.lphp.real {store_dir}\n",
      "    !rotate.pl {store_dir}/*.?HE.*.{t1}.{t2}.lphp.real\n",
      "    return r\n",
      "  \n",
      "    \n",
      "\n",
      "def plot_section_sac(event,channel=['HXZ','HXR','HXT'],filtername=False):\n",
      "    if filtername:\n",
      "        fs=glob.glob(os.path.joint(event,'*.'+channel+'.*'+'.'+filtername+'.synt'))\n",
      "        print os.path.join(event,'*.'+channel+'.*'+'.'+filtername+'.synt')\n",
      "    else:\n",
      "        fs=glob.glob(os.path.join(event,'*.*'+'.synt'))\n",
      "        print os.path.join(event,'*.*'+'.synt')\n",
      "    \n",
      "    rid=os.path.basename(event).split('_')[0]\n",
      "    stationfile=os.path.join(rid,'DATA/STATIONS')\n",
      "    cmt=os.path.join(rid,'DATA/CMTSOLUTION')\n",
      "    stations,nets,lat,lon=get_filteredstations(stationfile=stationfile)\n",
      "    lone,late,title=get_eventloc(cmt)\n",
      "    trs=[]\n",
      "    for f in fs:\n",
      "        st=obspy.core.read(f)\n",
      "        for v in st[:]:\n",
      "            stla = lat[stations==v.stats.station][0]\n",
      "            stlo = lon[stations==v.stats.station][0]\n",
      "            v.stats['coordinates']={'latitude':stla,'longitude':stlo}\n",
      "            v.stats['distance'] = obspy.core.util.gps2DistAzimuth(stla, stlo,\n",
      "                                        late, lone)[0]\n",
      "        trs.append(st[0])\n",
      "    stall=obspy.Stream(trs)\n",
      "    for ch in channel:\n",
      "        fig=plt.figure(figsize=(25,10))\n",
      "        sts=stall.select(channel=ch)\n",
      "        namepng=os.path.join(event,rid+'_sectionplot_'+ch+'.png')\n",
      "        print namepng\n",
      "        sts.plot(fig=fig,output=namepng,type='section',norm='trace',time_down=True,scale=10,alpha=0.4,color='red',plot_dx=100000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "def form_wild(formato,list_var=['channel'],list_subs=['HH[RTZ]']):\n",
      "    form=formato.split('.')\n",
      "    list_i=[]\n",
      "    for l in list_var:\n",
      "        list_i.append(form.index(l))\n",
      "    form=['*']*len(form)\n",
      "    for i,s in zip(list_i,list_subs):\n",
      "        form[i]=s\n",
      "    return '.'.join(form)\n",
      "\n",
      "def form_get(basename,formato,list_var=['channel']):\n",
      "    form=formato.split('.')\n",
      "    bform=basename.split('.')\n",
      "    list_i=[]\n",
      "    for l in list_var:\n",
      "        list_i.append(bform[form.index(l)])\n",
      "    return list_i\n",
      "\n",
      "def create_input_flexwin(dr,ds,t1='10',t2='40'):\n",
      "    if not os.path.exists(os.path.join(os.path.abspath(ds),'flexwin'+'_'+t1+'.'+t2)):    \n",
      "        os.mkdir(os.path.join(os.path.abspath(ds),'flexwin'+'_'+t1+'.'+t2))\n",
      "    inputname=os.path.join(os.path.abspath(ds),'flexwin'+'_'+t1+'.'+t2,'input_flexwin_cluster.txt')\n",
      "    inputfile=open(inputname,'w')\n",
      "    DATA_FILES=glob.glob(os.path.join(dr,form_wild(formato_data,['channel','ext','t1','t2'],[channel_data,ext_data,t1,t2])))\n",
      "    SYNT_FILES=glob.glob(os.path.join(ds,form_wild(formato_data,['channel','ext','t1','t2'],[channel_synt,ext_synt,t1,t2])))\n",
      "    inputstr=''\n",
      "    for d in DATA_FILES:\n",
      "        dbasename=os.path.basename(d)\n",
      "        ch,sta,net=form_get(dbasename,formato_data,list_var=['channel','station','network'])\n",
      "        fs=os.path.join(ds,form_wild(formato_synt,['channel','ext','station','network'],[channel_synt[0:2]+ch[2],ext_synt,sta,net]))\n",
      "        s=glob.glob(fs)\n",
      "        if len(s) > 0: \n",
      "            inputstr=inputstr+d+'\\n'+s[0]+'\\n'+ds+'/flexwin'+'_'+t1+'.'+t2+'/'+net+'.'+sta+'.'+ch+'\\n'\n",
      "            #else:\n",
      "            #    print 'no data ',net,sta,ch\n",
      "    inputstr=str(len(inputstr.split('\\n'))/3)+'\\n'+inputstr\n",
      "    inputfile.write(inputstr)\n",
      "    inputfile.close()\n",
      "    return dr,ds,inputname\n",
      "\n",
      "def run_flexwin(inputfile):\n",
      "    status=inputfile\n",
      "    _=!/ccc/cont005/home/ra2410/magnonif/flexwin_new/flexwin < {inputfile} > {inputfile}.log\n",
      "    mw=!ls {os.path.dirname(inputfile)}/MEASUREMENT.WINDOWS\n",
      "    return mw"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def check_sampling(d,s):\n",
      "    data=osbpy.read(d)\n",
      "    synt=osbpy.read(s)\n",
      "    return data[0].stats.sampling_rate==synt[0].stats.sampling_rate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "def collect_meas_window(d):                                   \n",
      "        !ls {d}/*.mt_input | wc -l > {d}/MEASUREMENT.WINDOWS\n",
      "        !cat {d}/*.mt_input >> {d}/MEASUREMENT.WINDOWS\n",
      "        return d\n",
      "\n",
      "def get_baz(s):\n",
      "    \"\"\"extract station-event back azimuth return baz (degree),bazr (radians)\"\"\"\n",
      "    v=obspy.read(s)[0]\n",
      "    _,az,baz=obspy.core.util.gps2DistAzimuth(v.stats.sac.stla, v.stats.sac.stlo,v.stats.sac.evla, v.stats.sac.evlo)\n",
      "    bazr=math.radians(baz)\n",
      "    return baz,bazr\n",
      "\n",
      "def update_sac_files(l):\n",
      "    fs=glob.glob(os.path.join(l,'run*.synt'))\n",
      "    for s in fs:\n",
      "        v=obspy.read(s)[0]\n",
      "        try:\n",
      "            if v.sac.az == -12345.0:\n",
      "                v.stats.sac.dist,v.stats.sac.az,v.stats.sac.baz=obspy.core.util.gps2DistAzimuth(v.stats.sac.stla, v.stats.sac.stlo,v.stats.sac.evla, v.stats.sac.evlo)\n",
      "            v.write(s,format='SAC')\n",
      "            return s\n",
      "        except:\n",
      "            print 'error',s\n",
      "            return v.stats\n",
      "\n",
      "\n",
      "def run_madj(l,CORRECT_PATH=True):\n",
      "    if not os.path.exists(os.path.join(l,'madj')): os.mkdir(os.path.join(l,'madj'))\n",
      "    !cp  MEASUREMENT.PAR {l}/madj/\n",
      "    !cp  measure_adj {l}/madj/\n",
      "    !cp  rotate_adj_src {l}/madj/\n",
      "    !cp  {l}/flexwin_*/MEASUREMENT.WINDOWS {l}/madj/\n",
      "    if not os.path.exists(os.path.join(l,'madj','OUTPUT_FILES')): os.mkdir(os.path.join(l,'madj','OUTPUT_FILES'))\n",
      "    #\n",
      "    back=!pwd\n",
      "    os.chdir(os.path.join(l,'madj'))\n",
      "    if CORRECT_PATH: add_full_path(back[0])\n",
      "    !measure_adj > madj.out\n",
      "    os.chdir(os.path.join(back[0]))\n",
      "    #!echo 'end' > madj.end\n",
      "    return l\n",
      "\n",
      "    \n",
      "def back_rotate(l):\n",
      "    back=!pwd\n",
      "    back=back[0]\n",
      "    os.chdir(os.path.join(l,'madj'))\n",
      "    adjs=glob.glob('OUTPUT_FILES/*.adj')\n",
      "    if len(adjs) > 0:\n",
      "        stations=numpy.unique([os.path.basename(x).split('.')[0] for x in adjs])\n",
      "        ch=os.path.basename(adjs[0]).split('.')[2][0:2]\n",
      "        for st in stations:\n",
      "            a=glob.glob('OUTPUT_FILES/'+st+'*.adj')[0]\n",
      "            net=os.path.basename(a).split('.')[1]\n",
      "            m=os.path.basename(a).split('.')[3]\n",
      "            s=glob.glob(os.path.join(back,l,'*.'+st+'.*'+'.?XZ.*.synt'))[0]\n",
      "            _,baz=get_baz(s)\n",
      "            zcomp='.'.join([st,net,ch+'Z',m,'adj'])\n",
      "            tcomp='.'.join([st,net,ch+'T',m,'adj'])\n",
      "            rcomp='.'.join([st,net,ch+'R',m,'adj'])\n",
      "            ecomp='.'.join([st,net,ch+'E',m,'adj'])\n",
      "            ncomp='.'.join([st,net,ch+'N',m,'adj'])\n",
      "            baz=str(baz)\n",
      "            text=' '.join([baz,'OUTPUT_FILES/'+zcomp,'OUTPUT_FILES/'+tcomp,'OUTPUT_FILES/'+rcomp,'OUTPUT_FILES/'+ecomp,'OUTPUT_FILES/'+ncomp])\n",
      "            !rotate_adj_src {text}\n",
      "            !cp {'OUTPUT_FILES/'+zcomp} {'OUTPUT_FILES/'+'.'.join([st,net,ch+'Z',m,'adj'])}\n",
      "        os.chdir(os.path.join(back))\n",
      "    else:\n",
      "        os.chdir(os.path.join(back))\n",
      "        return '0 adjs',l    \n",
      "\n",
      "def rename_adj(l,delimiter='iker07',channel='HX'):\n",
      "    back=!pwd\n",
      "    back=back[0]\n",
      "    os.chdir(l)\n",
      "    listfiles=glob.glob('*'+delimiter+'*.adj')\n",
      "    for f in listfiles:\n",
      "        name='.'.join(f.split('.'+delimiter+'.'))\n",
      "        !mv {f} {name}\n",
      "    listfiles=glob.glob('*.adj')\n",
      "    for f in listfiles:\n",
      "        splitted_name=f.split('.')\n",
      "        splitted_name[2]=channel+splitted_name[2][2]\n",
      "        name='.'.join(splitted_name)\n",
      "        !mv {f} {name}\n",
      "    os.chdir(os.path.join(back))\n",
      "    return l\n",
      "\n",
      "def adjust_time(l,start=-0.1,end=299.89,step=0.01):\n",
      "    \"\"\"\n",
      "    adjiust the length of the adj source\n",
      "    l :: directory with adj files\n",
      "    start :: starting point for time in the synth seismograms in specfem3d\n",
      "    end :: end point for time in the synth seismograms in specfem3d\n",
      "    step :: dt of simulation, see par_file\n",
      "    \"\"\"\n",
      "    adjs=glob.glob(os.path.join(l,'*.adj'))\n",
      "    for i,f in enumerate(adjs):\n",
      "        t,d=numpy.loadtxt(f,unpack=True)\n",
      "        c=(t>=start) & (t<=end)\n",
      "        npts=int((end-start)/step)+1\n",
      "        t1=numpy.arange(start,t[0]-step/2.,step)\n",
      "        t2=t[c]\n",
      "        t3=numpy.arange(t[-1]+step,end+step/2.,step)\n",
      "        d1=numpy.zeros(len(t1))\n",
      "        d2=d[c]\n",
      "        d3=numpy.zeros(len(t3))\n",
      "        t=numpy.concatenate([t1,t2,t3])\n",
      "        d=numpy.concatenate([d1,d2,d3])\n",
      "        try:\n",
      "            if len(t) == npts: \n",
      "                numpy.savetxt(f, numpy.c_[t,d])\n",
      "            else:\n",
      "                print len(t), l\n",
      "        except:\n",
      "            numpy.savetxt('tmp', numpy.c_[t,d])\n",
      "            !mv tmp {f} \n",
      "    return l\n",
      "\n",
      "def create_stations_adj(l):\n",
      "    import re\n",
      "    regex = re.compile(\"[.+r|r]un(.+)_mseed.+\")\n",
      "    id_run = regex.findall(l)[0]\n",
      "    back=!pwd\n",
      "    back=back[0]\n",
      "    \n",
      "    adjs=glob.glob(os.path.join(l,'*HXZ*.adj'))\n",
      "    stations_name=numpy.unique([os.path.basename(x).split('.')[0] for x in adjs])\n",
      "    stations_run=open(os.path.join('run'+id_run,'DATA','STATIONS'),'r').readlines()\n",
      "    if not os.path.exists(os.path.join(back+'_adj','run'+id_run,'DATA')): \n",
      "        os.mkdir(os.path.join(back+'_adj','run'+id_run,'DATA'))\n",
      "    stations_adj=open(os.path.join(back+'_adj','run'+id_run,'DATA','STATIONS_ADJOINT'),'w')\n",
      "    for line in stations_run:\n",
      "        st=line.split()[0]\n",
      "        print line\n",
      "        print st\n",
      "        for s in stations_name:\n",
      "           if s==st: \n",
      "                print 'name'\n",
      "                stations_adj.write(line)\n",
      "    stations_adj.close()\n",
      "    return l\n",
      "\n",
      "def move_adj_sem(l):\n",
      "    import re\n",
      "    regex = re.compile(\"[.+r|r]un(.+)_mseed.+\")\n",
      "    id_run = regex.findall(l)[0]\n",
      "    back=!pwd\n",
      "    back=back[0]\n",
      "    if not os.path.exists(os.path.join(back+'_adj','run'+id_run,'SEM')): \n",
      "        os.mkdir(os.path.join(back+'_adj','run'+id_run,'SEM'))\n",
      "    !mv {l}/*.*.??N.adj ../CMTs_adj/run{id_run}/SEM\n",
      "    !mv {l}/*.*.??E.adj ../CMTs_adj/run{id_run}/SEM\n",
      "    !mv {l}/*.*.??Z.adj ../CMTs_adj/run{id_run}/SEM\n",
      "    return os.path.join(back+'_adj','run'+id_run,'SEM')\n",
      "\n",
      "def add_full_path(back):\n",
      "    lines=open('MEASUREMENT.WINDOWS','r').readlines()\n",
      "    newfile=open('MEASUREMENT.WINDOWS','w')\n",
      "    for line in lines:\n",
      "        if line[0:3] == 'run':\n",
      "            newfile.write(back+'/'+line)\n",
      "        else:\n",
      "            newfile.write(line)\n",
      "    newfile.close()\n",
      "            \n",
      "        \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_id_run(text):\n",
      "    import re\n",
      "    regex = re.compile(\"[.+r|r]un(.+)_mseed.+\")\n",
      "    id_run = regex.findall(text)[0]\n",
      "    return id_run\n",
      "\n",
      "def get_id_iteration(text):\n",
      "    import re\n",
      "    regex = re.compile(\"(s[0-9]+_m[0-9]+).+\")\n",
      "    try:\n",
      "        id_run = regex.findall(text)[0]\n",
      "    except:\n",
      "        id_run=-1   \n",
      "    return id_run\n",
      "\n",
      "def get_data(dir_adjs):\n",
      "        import os\n",
      "        win_file='window_chi'\n",
      "        adjs=glob.glob(dir_adjs)\n",
      "        wadj=[]\n",
      "        runs=[]\n",
      "        iterations=[]\n",
      "        wchiflag=False\n",
      "        for adj in adjs:\n",
      "            id_run=get_id_run(adj)\n",
      "            id_it=get_id_iteration(adj)\n",
      "            station_name=os.path.join(adj.split('_')[0],'DATA','STATIONS')\n",
      "            cmt_name=os.path.join(adj.split('_')[0],'DATA','CMTSOLUTION')\n",
      "            chiname=os.path.join(adj,win_file)\n",
      "            try:\n",
      "                if not wchiflag:\n",
      "                    wchi=ps.read_csv(chiname,header=None,sep='\\s*',engine='python',names=names_cols)\n",
      "                    nw=len(wchi)\n",
      "                    wchi['run']=[id_run]*nw\n",
      "                    wchi['it']=[id_it]*nw\n",
      "                    wchi['wdt']=wchi['tend']-wchi['tstart']\n",
      "                    runs.append(id_run)\n",
      "                    iterations.append(id_it)\n",
      "                    wchiflag=True\n",
      "                else:\n",
      "                    wchi_tmp=ps.read_csv(chiname,header=None,sep='\\s*',engine='python',names=names_cols)\n",
      "                    nw=len(wchi_tmp)\n",
      "                    wchi_tmp['run']=[id_run]*nw\n",
      "                    wchi_tmp['it']=[id_it]*nw\n",
      "                    wchi['wdt']=wchi['tend']-wchi['tstart']\n",
      "                    runs.append(id_run)\n",
      "                    iterations.append(id_it)\n",
      "                    wchi=ps.concat([wchi,wchi_tmp])\n",
      "            except:\n",
      "                import os\n",
      "                os.system('wc '+chiname)\n",
      "        return wchi\n",
      "                "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#EXCUTE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "SYNT='run*_mseed_processed'\n",
      "channel_data='HH[RTZ]'\n",
      "channel_synt='HX[RTZ]'\n",
      "formato_data='*.network.station..channel.letter.*.t1.t2.*.ext'\n",
      "formato_synt=formato_data\n",
      "ext_data='real'\n",
      "ext_synt='synt'\n",
      "t1='10'\n",
      "t2='40'\n",
      "sampling=20\n",
      "DATA_ARCHIVE='/ccc/work/cont005/ra2410/magnonif/DATA_STORE'\n",
      "DATA=os.path.join(DATA_ARCHIVE,'run*_mseed_processed'+'_'+str(sampling)+'_'+t1+'.'+t2)\n",
      "id_event='????'\n",
      "#id_event='????'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PROCESSING_DATA=False\n",
      "FLAG_CREATE_MSEED=False\n",
      "FLAG_PROCESSING_SYNT=False\n",
      "PROCESSING_FLEXWIN=False\n",
      "PROCESSING_MADJ=False\n",
      "CLEAN_MADJ=False\n",
      "CALCULATE_MISFIT=False\n",
      "if os.environ.get('PROCESSING_DATA')=='True':PROCESSING_DATA=True\n",
      "if os.environ.get('FLAG_CREATE_MSEED')=='True':FLAG_CREATE_MSEED=True\n",
      "if os.environ.get('FLAG_PROCESSING_SYNT')=='True':FLAG_PROCESSING_SYNT=True\n",
      "if os.environ.get('PROCESSING_FLEXWIN')=='True':PROCESSING_FLEXWIN=True\n",
      "if os.environ.get('PROCESSING_MADJ')=='True':PROCESSING_MADJ=True\n",
      "if os.environ.get('CLEAN_MADJ')=='True':CLEAN_MADJ=True\n",
      "if os.environ.get('CALCULATE_MISFIT')=='True':CALCULATE_MISFIT=True\n",
      "print  PROCESSING_DATA,FLAG_CREATE_MSEED,FLAG_PROCESSING_SYNT,PROCESSING_FLEXWIN,PROCESSING_MADJ,CLEAN_MADJ"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if PROCESSING_DATA:\n",
      "    mseeds_dirs=glob.glob(os.path.join(DATA_ARCHIVE,'run*_mseed'))\n",
      "    result=view.map(process_data,mseeds_dirs[:])\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if FLAG_CREATE_MSEED:\n",
      "    rs=glob.glob('run'+id_event)\n",
      "    result=view.map(create_mseed,rs[:])\n",
      "    while not result.ready():\n",
      "        continue\n",
      "    print result.result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if FLAG_PROCESSING_SYNT:\n",
      "    mseeds=glob.glob('run*_semv.mseed')\n",
      "    result=view.map(extract_sac,mseeds[:])\n",
      "    while not result.ready():\n",
      "        continue\n",
      "    print result.result\n",
      "    \n",
      "    mseeds_dirs=glob.glob('run*_mseed')\n",
      "    result=view.map(process_synt,mseeds_dirs[:])\n",
      "    while not result.ready():\n",
      "        continue\n",
      "    print result.result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#FLEXWIN\n",
      "if PROCESSING_FLEXWIN:\n",
      "    DATA_DIRS=sorted(glob.glob(DATA))\n",
      "    SYNT_DIRS=sorted(glob.glob(SYNT))\n",
      "    if len(DATA_DIRS) != len(SYNT_DIRS):\n",
      "        DATA_DIRS=[]\n",
      "        for s in SYNT_DIRS:\n",
      "            txt=os.path.join(DATA_ARCHIVE,os.path.basename(s)+'_'+str(sampling)+'_'+t1+'.'+t2)\n",
      "            DATA_DIRS.append(txt)\n",
      "\n",
      "    result=view.map(create_input_flexwin,DATA_DIRS[:],SYNT_DIRS[:])\n",
      "    while not result.ready():\n",
      "        continue\n",
      "    print result.result\n",
      "\n",
      "    flex_DIRS=glob.glob(os.path.join(SYNT,'flexwin'+'_'+t1+'.'+t2+'/input_flexwin_cluster.txt'))\n",
      "    result=view.map(run_flexwin,flex_DIRS[:])\n",
      "    while not result.ready():\n",
      "        continue\n",
      "    print result.result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#MEASURE ADJ"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if PROCESSING_MADJ:\n",
      "    ls=glob.glob('run*_mseed_processed/flexwin_10.40')\n",
      "    result=view.map(collect_meas_window,ls)\n",
      "    while not result.ready():\n",
      "        continue\n",
      "    print result.result\n",
      "    \n",
      "    ls=glob.glob('run*_mseed_processed/')\n",
      "    result=view.map(update_sac_files,ls)\n",
      "    while not result.ready():\n",
      "        continue\n",
      "    print result.result\n",
      "\n",
      "    result=view.map(run_madj,ls)\n",
      "    while not result.ready():\n",
      "        continue\n",
      "    print result.result\n",
      "    \n",
      "if CLEAN_MADJ:\n",
      "\n",
      "    ls=glob.glob('run*_mseed_processed/')\n",
      "    result=view.map(back_rotate,ls)\n",
      "    while not result.ready():\n",
      "        continue\n",
      "    print result.result\n",
      "\n",
      "    ls=glob.glob('run*_mseed_processed/madj/OUTPUT_FILES/')\n",
      "    result=view.map(rename_adj,ls)\n",
      "    while not result.ready():\n",
      "        continue\n",
      "    print result.result\n",
      "    \n",
      "    result=view.map(adjust_time,ls)\n",
      "    while not result.ready():\n",
      "        continue\n",
      "    print result.result\n",
      "\n",
      "    result=view.map(create_stations_adj,ls)\n",
      "    while not result.ready():\n",
      "        continue\n",
      "    print result.result\n",
      "\n",
      "    result=view.map(move_adj_sem,ls)\n",
      "    while not result.ready():\n",
      "        continue\n",
      "    print result.result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if CALCULATE_MISFIT:\n",
      "    names_cols=['name', 'station', 'network','channel','windows_id','measurement_type','tstart','tend','_8','_9','chidt','chidlnA',\n",
      "            '_12','_13','xcdt','xcdlnA','_16','_17','_18','_19','window_power','_21','_22','_23','_24','record_power',\n",
      "            '_26','_27','ttchi','amchi','_30','_31']\n",
      "    dir_adjs='run*_mseed_processed/madj'\n",
      "    win_file='window_chi'\n",
      "    wchi_iterations=get_data(dir_adjs)\n",
      "    iterations=sorted(numpy.unique(wchi_iterations['it']))\n",
      "\n",
      "    for i,current_iteration in enumerate(iterations):\n",
      "        wchi=wchi_iterations[wchi_iterations['it']==current_iteration]\n",
      "        stations=numpy.unique(wchi['station'])\n",
      "        listch=wchi['channel'].unique()\n",
      "        runs=wchi['run'].unique()\n",
      "\n",
      "        for l in listch:\n",
      "            wchi['channel'][wchi['channel']==l]=l[2]\n",
      "\n",
      "        listch=wchi['channel'].unique()\n",
      "    \n",
      "        nozero=wchi[wchi['ttchi']!=0.]\n",
      "        R=nozero[nozero['channel']=='R']\n",
      "        Z=nozero[nozero['channel']=='Z']\n",
      "        T=nozero[nozero['channel']=='T']\n",
      "        kernels=[nozero['ttchi'].mean(),R['ttchi'].mean(),T['ttchi'].mean(),Z['ttchi'].mean(),len(nozero['ttchi']),\n",
      "             len(R['ttchi']),len(T['ttchi']),len(Z['ttchi']),nozero['wdt'].sum(),R['wdt'].sum(),T['wdt'].sum(),Z['wdt'].sum()]\n",
      "\n",
      "    \n",
      "        if current_iteration==iterations[-1]:\n",
      "            g=open('misfit_value.txt','w')\n",
      "            g.write(str(nozero['ttchi'].mean())+' '+str(R['ttchi'].mean())+' '+str(T['ttchi'].mean())+' '+str(Z['ttchi'].mean()))\n",
      "            g.close()\n",
      "            print current_iteration\n",
      "            print 'tot misfit function :',nozero['ttchi'].mean(), 'number window :', len(nozero['ttchi']),'time :',nozero['wdt'].sum()\n",
      "            print 'R misfit function :',R['ttchi'].mean(), 'number window :', len(R['ttchi']),'time :',R['wdt'].sum()\n",
      "            print 'T misfit function :',T['ttchi'].mean(), 'number window :', len(T['ttchi']),'time :',T['wdt'].sum()\n",
      "            print 'Z misfit function :',Z['ttchi'].mean(), 'number window :', len(Z['ttchi']),'time :',Z['wdt'].sum()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}